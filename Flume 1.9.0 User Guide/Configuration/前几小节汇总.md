# 前几小节汇总

[TOC]

> As mentioned in the earlier section, Flume agent configuration is read from a file that resembles a Java property file format with hierarchical property settings.

如前一节所述，Flume agent 配置是从一个文件中读取的，该文件类似于具有分层属性设置的 Java 属性文件格式。

## 1、Defining the flow

> To define the flow within a single agent, you need to link the sources and sinks via a channel. You need to list the sources, sinks and channels for the given agent, and then point the source and sink to a channel. A source instance can specify multiple channels, but a sink instance can only specify one channel. The format is as follows:

在一个 agent 中定义流，你需要通过 channel 连接 sources 和 sinks。

对给定的 agent，你需要**列出 sources、sinks 和 channels**。

然后将 sources 和 sinks **指向 一个 channels**。

**一个 source 实例可以指定多个 channels，但一个 sink 实例只能指定一个 channel**。格式如下：

	# list the sources, sinks and channels for the agent
	<Agent>.sources = <Source>
	<Agent>.sinks = <Sink>
	<Agent>.channels = <Channel1> <Channel2>

	# set channel for source
	<Agent>.sources.<Source>.channels = <Channel1> <Channel2> ...

	# set channel for sink
	<Agent>.sinks.<Sink>.channel = <Channel1>

> For example, an agent named agent_foo is reading data from an external avro client and sending it to HDFS via a memory channel. The config file weblog.config could look like:

例如，一个名为 agent_foo 的 agent 正在从一个外部 avro 客户端读取数据，并通过一个内存 channel 将其发送到 HDFS。配置文件 weblog.config 如下所示：

	# list the sources, sinks and channels for the agent
	agent_foo.sources = avro-appserver-src-1
	agent_foo.sinks = hdfs-sink-1
	agent_foo.channels = mem-channel-1

	# set channel for source
	agent_foo.sources.avro-appserver-src-1.channels = mem-channel-1

	# set channel for sink
	agent_foo.sinks.hdfs-sink-1.channel = mem-channel-1

> This will make the events flow from avro-AppSrv-source to hdfs-Cluster1-sink through the memory channel mem-channel-1. When the agent is started with the weblog.config as its config file, it will instantiate that flow.

这将会让 events 通过内存 channel mem-channel-1 从 avro-AppSrv-source 流向 hdfs-Cluster1-sink。当使用 weblog.config 启动 agent 时，它将实例化那个流。

## 2、Configuring individual components

> After defining the flow, you need to set properties of each source, sink and channel. This is done in the same hierarchical namespace fashion where you set the component type and other values for the properties specific to each component:

在定义流之后，你需要**设置每个 source、sink 和 channel 的属性**。

这是在相同层次的命名空间中完成的，在这里，设置组件类型和特定于每个组件的属性的其他值:

	# properties for sources
	<Agent>.sources.<Source>.<someProperty> = <someValue>

	# properties for channels
	<Agent>.channel.<Channel>.<someProperty> = <someValue>

	# properties for sinks
	<Agent>.sources.<Sink>.<someProperty> = <someValue>

> The property “type” needs to be set for each component for Flume to understand what kind of object it needs to be. Each source, sink and channel type has its own set of properties required for it to function as intended. All those need to be set as needed. In the previous example, we have a flow from avro-AppSrv-source to hdfs-Cluster1-sink through the memory channel mem-channel-1. Here’s an example that shows configuration of each of those components:

需要给每个 Flume 组件设置属性 “type”，来理解需要哪种对象。每个 source、sink 和 channel 类型都有它自己的功能所需的属性集。 这些属性需要按需设置。在前面的例子中，我们有一个通过内存 channel mem-channel-1 从 avro-AppSrv-source 向 hdfs-Cluster1-sink 的流。这里是一个展示每个组件配置的示例：

	agent_foo.sources = avro-AppSrv-source
	agent_foo.sinks = hdfs-Cluster1-sink
	agent_foo.channels = mem-channel-1

	# set channel for sources, sinks

	# properties of avro-AppSrv-source
	agent_foo.sources.avro-AppSrv-source.type = avro
	agent_foo.sources.avro-AppSrv-source.bind = localhost
	agent_foo.sources.avro-AppSrv-source.port = 10000

	# properties of mem-channel-1
	agent_foo.channels.mem-channel-1.type = memory
	agent_foo.channels.mem-channel-1.capacity = 1000
	agent_foo.channels.mem-channel-1.transactionCapacity = 100

	# properties of hdfs-Cluster1-sink
	agent_foo.sinks.hdfs-Cluster1-sink.type = hdfs
	agent_foo.sinks.hdfs-Cluster1-sink.hdfs.path = hdfs://namenode/flume/webdata

	#...

## 3、Adding multiple flows in an agent

> A single Flume agent can contain several independent flows. You can list multiple sources, sinks and channels in a config. These components can be linked to form multiple flows:

**一个 Flume agent 可以包含多个独立的流**。你可以在配置中列出多个 source、sink 和 channel。连接这些组件形成多个流：

	# list the sources, sinks and channels for the agent
	<Agent>.sources = <Source1> <Source2>
	<Agent>.sinks = <Sink1> <Sink2>
	<Agent>.channels = <Channel1> <Channel2>

> Then you can link the sources and sinks to their corresponding channels (for sources) of channel (for sinks) to setup two different flows. For example, if you need to setup two flows in an agent, one going from an external avro client to external HDFS and another from output of a tail to avro sink, then here’s a config to do that:

然后你可以连接 sources 和 sinks 到它们对应的 channels，以设置两个不同的流。

例如，如果你需要在一个 agent 中设置两个流，一个从外部 avro 客户端到外部 HDFS，另一个从尾部输出到 avro sink，那么这里有一个配置:

	# list the sources, sinks and channels in the agent
	agent_foo.sources = avro-AppSrv-source1 exec-tail-source2
	agent_foo.sinks = hdfs-Cluster1-sink1 avro-forward-sink2
	agent_foo.channels = mem-channel-1 file-channel-2

	# flow #1 configuration
	agent_foo.sources.avro-AppSrv-source1.channels = mem-channel-1
	agent_foo.sinks.hdfs-Cluster1-sink1.channel = mem-channel-1

	# flow #2 configuration
	agent_foo.sources.exec-tail-source2.channels = file-channel-2
	agent_foo.sinks.avro-forward-sink2.channel = file-channel-2

## 4、Configuring a multi agent flow

> To setup a multi-tier flow, you need to have an avro/thrift sink of first hop pointing to avro/thrift source of the next hop. This will result in the first Flume agent forwarding events to the next Flume agent. For example, if you are periodically sending files (1 file per event) using avro client to a local Flume agent, then this local agent can forward it to another agent that has the mounted for storage.

**要设置一个多层流，需要有一个第一跳的 avro/thrift sink 指向下一跳的 avro/thrift source**。

这将导致第一个 Flume agent 将 events 转发给下一个 Flume agent。

例如，如果使用 avro 客户端定期向本地 Flume agent 发送文件(每个 event 发送一个文件)，那么这个本地 agent 可以将其转发给另一个挂载了该文件的 agent 进行存储。

Weblog agent config:

	# list sources, sinks and channels in the agent
	agent_foo.sources = avro-AppSrv-source
	agent_foo.sinks = avro-forward-sink
	agent_foo.channels = file-channel

	# define the flow
	agent_foo.sources.avro-AppSrv-source.channels = file-channel
	agent_foo.sinks.avro-forward-sink.channel = file-channel

	# avro sink properties
	agent_foo.sinks.avro-forward-sink.type = avro
	agent_foo.sinks.avro-forward-sink.hostname = 10.1.1.100
	agent_foo.sinks.avro-forward-sink.port = 10000

	# configure other pieces
	#...

HDFS agent config:

	# list sources, sinks and channels in the agent
	agent_foo.sources = avro-collection-source
	agent_foo.sinks = hdfs-sink
	agent_foo.channels = mem-channel

	# define the flow
	agent_foo.sources.avro-collection-source.channels = mem-channel
	agent_foo.sinks.hdfs-sink.channel = mem-channel

	# avro source properties
	agent_foo.sources.avro-collection-source.type = avro
	agent_foo.sources.avro-collection-source.bind = 10.1.1.100
	agent_foo.sources.avro-collection-source.port = 10000

	# configure other pieces
	#...

> Here we link the avro-forward-sink from the weblog agent to the avro-collection-source of the hdfs agent. This will result in the events coming from the external appserver source eventually getting stored in HDFS.

这里我们将 weblog agent 的 avro-forward-sink 链接到 hdfs agent 的 avro-collect -source。

这将导致来自外部 appserver source 的 events 最终存储在 HDFS 中。

## 5、Fan out flow

> As discussed in previous section, Flume supports fanning out the flow from one source to multiple channels. There are two modes of fan out, replicating and multiplexing. In the replicating flow, the event is sent to all the configured channels. In case of multiplexing, the event is sent to only a subset of qualifying channels. To fan out the flow, one needs to specify a list of channels for a source and the policy for the fanning it out. This is done by adding a channel “selector” that can be replicating or multiplexing. Then further specify the selection rules if it’s a multiplexer. If you don’t specify a selector, then by default it’s replicating:

如前一节所讨论的，Flume 支持从一个 source 向多个 channels 扇出流。

有两种扇出模式，`replicating` 和 `multiplexing`。

在 `replicating` 流中，event 被发送到所有配置了的 channels。

在 `multiplexing` 的情况下，event 只被发送到限定 channels 的一个子集。

要扇出流，需要指定 source 的 channels 列表和展开的策略。这是通过添加一个可以 `replicating` 和 `multiplexing` 的 channel selector 来完成的。

如果是 `multiplexing`，则进一步指定选择规则。

如果你没有指定选择器，那么默认情况下它是 `replicating`:

	# List the sources, sinks and channels for the agent
	<Agent>.sources = <Source1>
	<Agent>.sinks = <Sink1> <Sink2>
	<Agent>.channels = <Channel1> <Channel2>

	# set list of channels for source (separated by space)
	<Agent>.sources.<Source1>.channels = <Channel1> <Channel2>

	# set channel for sinks
	<Agent>.sinks.<Sink1>.channel = <Channel1>
	<Agent>.sinks.<Sink2>.channel = <Channel2>

	<Agent>.sources.<Source1>.selector.type = replicating

> The multiplexing select has a further set of properties to bifurcate the flow. This requires specifying a mapping of an event attribute to a set for channel. The selector checks for each configured attribute in the event header. If it matches the specified value, then that event is sent to all the channels mapped to that value. If there’s no match, then the event is sent to set of channels configured as default:

`multiplexing` 选择具有进一步的属性集来分岔流。这需要指定一个 event 属性到一个 channel 集合的映射。

selector 检查 event header 中的每个配置的属性。如果它与指定的值匹配，则将该 event 发送到该值映射的所有 channels。如果没有匹配，那么 event 被发送到配置为默认的 channels 集合:

	# Mapping for multiplexing selector
	<Agent>.sources.<Source1>.selector.type = multiplexing
	<Agent>.sources.<Source1>.selector.header = <someHeader>
	<Agent>.sources.<Source1>.selector.mapping.<Value1> = <Channel1>
	<Agent>.sources.<Source1>.selector.mapping.<Value2> = <Channel1> <Channel2>
	<Agent>.sources.<Source1>.selector.mapping.<Value3> = <Channel2>
	#...

	<Agent>.sources.<Source1>.selector.default = <Channel2>

> The mapping allows overlapping the channels for each value.

映射允许每个值的 channels 重叠。

> The following example has a single flow that multiplexed to two paths. The agent named agent_foo has a single avro source and two channels linked to two sinks:

下面的示例有一个多路传输到两条路径的流。名为 agent_foo 的 agent 有一个 avro source 和连接到两个 sinks 的两个 channels:

	# list the sources, sinks and channels in the agent
	agent_foo.sources = avro-AppSrv-source1
	agent_foo.sinks = hdfs-Cluster1-sink1 avro-forward-sink2
	agent_foo.channels = mem-channel-1 file-channel-2

	# set channels for source
	agent_foo.sources.avro-AppSrv-source1.channels = mem-channel-1 file-channel-2

	# set channel for sinks
	agent_foo.sinks.hdfs-Cluster1-sink1.channel = mem-channel-1
	agent_foo.sinks.avro-forward-sink2.channel = file-channel-2

	# channel selector configuration
	agent_foo.sources.avro-AppSrv-source1.selector.type = multiplexing
	agent_foo.sources.avro-AppSrv-source1.selector.header = State
	agent_foo.sources.avro-AppSrv-source1.selector.mapping.CA = mem-channel-1
	agent_foo.sources.avro-AppSrv-source1.selector.mapping.AZ = file-channel-2
	agent_foo.sources.avro-AppSrv-source1.selector.mapping.NY = mem-channel-1 file-channel-2
	agent_foo.sources.avro-AppSrv-source1.selector.default = mem-channel-1

> The selector checks for a header called “State”. If the value is “CA” then its sent to mem-channel-1, if its “AZ” then it goes to file-channel-2 or if its “NY” then both. If the “State” header is not set or doesn’t match any of the three, then it goes to mem-channel-1 which is designated as ‘default’.

selector 检查名为 State 的 header。如果值是 CA，那么它被发送到 mems -channel-1，如果值是 AZ，那么它被发送到 file-channel-2，如果值是 NY，那么两者都发送。如果 State header 没有设置或者不匹配这三个报头中的任何一个，那么它将转到 mems-channel-1，它被指定为 default。

> The selector also supports optional channels. To specify optional channels for a header, the config parameter ‘optional’ is used in the following way:

selector 也支持可选的 channels。要为 header 指定可选的 channels，配置参数 optional 的用法如下:

	# channel selector configuration
	agent_foo.sources.avro-AppSrv-source1.selector.type = multiplexing
	agent_foo.sources.avro-AppSrv-source1.selector.header = State
	agent_foo.sources.avro-AppSrv-source1.selector.mapping.CA = mem-channel-1
	agent_foo.sources.avro-AppSrv-source1.selector.mapping.AZ = file-channel-2
	agent_foo.sources.avro-AppSrv-source1.selector.mapping.NY = mem-channel-1 file-channel-2
	agent_foo.sources.avro-AppSrv-source1.selector.optional.CA = mem-channel-1 file-channel-2
	agent_foo.sources.avro-AppSrv-source1.selector.mapping.AZ = file-channel-2
	agent_foo.sources.avro-AppSrv-source1.selector.default = mem-channel-1

> The selector will attempt to write to the required channels first and will fail the transaction if even one of these channels fails to consume the events. The transaction is reattempted on all of the channels. Once all required channels have consumed the events, then the selector will attempt to write to the optional channels. A failure by any of the optional channels to consume the event is simply ignored and not retried.

selector 将首先尝试写入所要求的 channels，如果这些 channels 中有一个无法消费 events，则这个事务将失败。在所有 channels 上将重新尝试这个事务。

一旦所有要求的 channels 都消费了 events，那么 selector 将尝试写入到可选的 channels。任何可选的 channels 消费 event 的失败都将被忽略，不会重试。

> If there is an overlap between the optional channels and required channels for a specific header, the channel is considered to be required, and a failure in the channel will cause the entire set of required channels to be retried. For instance, in the above example, for the header “CA” mem-channel-1 is considered to be a required channel even though it is marked both as required and optional, and a failure to write to this channel will cause that event to be retried on all channels configured for the selector.

如果特定 header 的可选 channels 和必需 channels 之间有重叠，则认为该 channel 是必需的，并且 channel 中的故障将导致整个必需 channels 集被重试。

例如，在上面的示例中，对于 header CA ，mem-channel-1 被认为是必需的 channel，即使它被标记为必需的和可选的，并且向该 channel 写入失败将导致在为 selector 配置的所有 channels 上重试该 event。

> Note that if a header does not have any required channels, then the event will be written to the default channels and will be attempted to be written to the optional channels for that header. Specifying optional channels will still cause the event to be written to the default channels, if no required channels are specified. If no channels are designated as default and there are no required, the selector will attempt to write the events to the optional channels. Any failures are simply ignored in that case.

注意，如果一个 header 没有任何必需的 channels，那么 event 将被写入默认 channels，并尝试写入该 header 的可选 channels。

如果没有指定必需的 channels，指定可选 channels 仍然会导致将 event 写入默认 channels。

如果没有指定默认 channels，也不需要，selector 将尝试将 events 写入可选 channels。

在这种情况下，任何失败都将被忽略。

## 6、SSL/TLS support

> Several Flume components support the SSL/TLS protocols in order to communicate with other systems securely.

Component    |   SSL server or client
---|:---
Avro Source  |   server
Avro Sink	 |   client
Thrift Source|	 server
Thrift Sink	 |   client
Kafka Source |	 client
Kafka Channel|	 client
Kafka Sink	 |   client
HTTP Source	 |   server
JMS Source	 |  client
Syslog TCP Source|	server
Multiport Syslog TCP Source	| server

> The SSL compatible components have several configuration parameters to set up SSL, like enable SSL flag, keystore / truststore parameters (location, password, type) and additional SSL parameters (eg. disabled protocols).

> Enabling SSL for a component is always specified at component level in the agent configuration file. So some components may be configured to use SSL while others not (even with the same component type).

> The keystore / truststore setup can be specified at component level or globally.

> In case of the component level setup, the keystore / truststore is configured in the agent configuration file through component specific parameters. The advantage of this method is that the components can use different keystores (if this would be needed). The disadvantage is that the keystore parameters must be copied for each component in the agent configuration file. The component level setup is optional, but if it is defined, it has higher precedence than the global parameters.

> With the global setup, it is enough to define the keystore / truststore parameters once and use the same settings for all components, which means less and more centralized configuration.

> The global setup can be configured either through system properties or through environment variables.

System property               |   Environment variable      |   Description
---|:---|:---
javax.net.ssl.keyStore	      |  FLUME_SSL_KEYSTORE_PATH	|  Keystore location
javax.net.ssl.keyStorePassword|	 FLUME_SSL_KEYSTORE_PASSWORD|  Keystore password
javax.net.ssl.keyStoreType	  |  FLUME_SSL_KEYSTORE_TYPE	|  Keystore type (by default JKS)
javax.net.ssl.trustStore	  |  FLUME_SSL_TRUSTSTORE_PATH	|  Truststore location
javax.net.ssl.trustStorePassword|FLUME_SSL_TRUSTSTORE_PASSWORD |	Truststore password
javax.net.ssl.trustStoreType  |	 FLUME_SSL_TRUSTSTORE_TYPE	|  Truststore type (by default JKS)
flume.ssl.include.protocols	  |  FLUME_SSL_INCLUDE_PROTOCOLS|  Protocols to include when calculating enabled protocols. A comma (,) separated list. Excluded protocols will be excluded from this list if provided.
flume.ssl.exclude.protocols	  |  FLUME_SSL_EXCLUDE_PROTOCOLS|  Protocols to exclude when calculating enabled protocols. A comma (,) separated list.
flume.ssl.include.cipherSuites|	 FLUME_SSL_INCLUDE_CIPHERSUITES	 |  Cipher suites to include when calculating enabled cipher suites. A comma (,) separated list. Excluded cipher suites will be excluded from this list if provided.
flume.ssl.exclude.cipherSuites|	FLUME_SSL_EXCLUDE_CIPHERSUITES  |  Cipher suites to exclude when calculating enabled cipher suites. A comma (,) separated list.

> The SSL system properties can either be passed on the command line or by setting the JAVA_OPTS environment variable in conf/flume-env.sh. (Although, using the command line is inadvisable because the commands including the passwords will be saved to the command history.)

	export JAVA_OPTS="$JAVA_OPTS -Djavax.net.ssl.keyStore=/path/to/keystore.jks"
	export JAVA_OPTS="$JAVA_OPTS -Djavax.net.ssl.keyStorePassword=password"

> Flume uses the system properties defined in JSSE (Java Secure Socket Extension), so this is a standard way for setting up SSL. On the other hand, specifying passwords in system properties means that the passwords can be seen in the process list. For cases where it is not acceptable, it is also be possible to define the parameters in environment variables. Flume initializes the JSSE system properties from the corresponding environment variables internally in this case.

> The SSL environment variables can either be set in the shell environment before starting Flume or in conf/flume-env.sh. (Although, using the command line is inadvisable because the commands including the passwords will be saved to the command history.)

	export FLUME_SSL_KEYSTORE_PATH=/path/to/keystore.jks
	export FLUME_SSL_KEYSTORE_PASSWORD=password

> Please note:

- SSL must be enabled at component level. Specifying the global SSL parameters alone will not have any effect.

- If the global SSL parameters are specified at multiple levels, the priority is the following (from higher to lower):

	- component parameters in agent config
	- system properties
	- environment variables

- If SSL is enabled for a component, but the SSL parameters are not specified in any of the ways described above, then

	- in case of keystores: configuration error
	- in case of truststores: the default truststore will be used (jssecacerts / cacerts in Oracle JDK)

- The trustore password is optional in all cases. If not specified, then no integrity check will be performed on the truststore when it is opened by the JDK.

## 7、Source and sink batch sizes and channel transaction capacities

> Sources and sinks can have a batch size parameter that determines the maximum number of events they process in one batch. This happens within a channel transaction that has an upper limit called transaction capacity. Batch size must be smaller than the channel’s transaction capacity. There is an explicit check to prevent incompatible settings. This check happens whenever the configuration is read.

Sources 和 sinks 有一个 batch size 参数，它决定了在一个批次中处理 events 的最大数量。

这在一个 channel 事务中发送，channel 事务有一个上层限制，称为 transaction capacity。

**batch size 必须小于 channel 的 transaction capacity。【会自动报错】**

存在一个明确的检查，来阻止不兼容的配置。只有读取了配置，检查就会发生。